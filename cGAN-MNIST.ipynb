{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15789,"status":"ok","timestamp":1656689725854,"user":{"displayName":"Люда Штенгауэр","userId":"07305707816373708016"},"user_tz":-180},"id":"Ijn8ZRSgIk5f","outputId":"eed874de-dd8b-4fe5-bab9-589caa799fcb"},"outputs":[{"name":"stdout","output_type":"stream","text":["  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q git+https://github.com/tensorflow/docs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJCR5M4IIrpx"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow_docs.vis import embed\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","import imageio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6kjrRjiItsu"},"outputs":[],"source":["# константы\n","batch_size = 64\n","nc = 1\n","n_classes = 10\n","image_size = 28\n","latent_dim = 128"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1181,"status":"ok","timestamp":1656690632721,"user":{"displayName":"Люда Штенгауэр","userId":"07305707816373708016"},"user_tz":-180},"id":"XTmZjoqeIxRx","outputId":"805821a8-f437-4d95-83a0-58d6689ec294"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}],"source":["# Загрузка набора данных MNIST и его предварительная обработка\n","\n","(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","all_digits = np.concatenate([x_train, x_test])\n","all_labels = np.concatenate([y_train, y_test])\n","\n","all_digits = all_digits.astype(\"float32\") / 255.0\n","all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n","all_labels = keras.utils.to_categorical(all_labels, 10)\n","\n","dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))\n","dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aMaec0ORI736"},"outputs":[],"source":["# Расчет количества входных каналов для генератора и дискриминатора\n","generator_channels = latent_dim + n_classes\n","discriminator_channels = nc + n_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NfhXFbBRJEuB"},"outputs":[],"source":["# Создание дискриминатора и генератора\n","discriminator = keras.Sequential(\n","    [\n","        keras.layers.InputLayer((28, 28, discriminator_channels)),\n","        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.GlobalMaxPooling2D(),\n","        layers.Dense(1),\n","    ],\n","    name=\"discriminator\",\n",")\n","\n","\n","generator = keras.Sequential(\n","    [\n","        keras.layers.InputLayer((generator_channels,)),\n","        layers.Dense(7 * 7 * generator_channels),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Reshape((7, 7, generator_channels)),\n","        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n","    ],\n","    name=\"generator\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"glgbWn74JQrx"},"outputs":[],"source":["# Создание Conditional GAN модели\n","class ConditionalGAN(keras.Model):\n","    def __init__(self, discriminator, generator, latent_dim):\n","        super(ConditionalGAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n","        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [self.gen_loss_tracker, self.disc_loss_tracker]\n","\n","    def compile(self, d_optimizer, g_optimizer, loss_fn):\n","        super(ConditionalGAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.loss_fn = loss_fn\n","\n","    def train_step(self, data):\n","        real_images, one_hot_labels = data\n","\n","        image_one_hot_labels = one_hot_labels[:, :, None, None]\n","        image_one_hot_labels = tf.repeat(\n","            image_one_hot_labels, repeats=[image_size * image_size]\n","        )\n","        image_one_hot_labels = tf.reshape(\n","            image_one_hot_labels, (-1, image_size, image_size, n_classes)\n","        )\n","\n","      \n","        batch_size = tf.shape(real_images)[0]\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        random_vector_labels = tf.concat(\n","            [random_latent_vectors, one_hot_labels], axis=1\n","        )\n","\n","        generated_images = self.generator(random_vector_labels)\n","\n","        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n","        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n","        combined_images = tf.concat(\n","            [fake_image_and_labels, real_image_and_labels], axis=0\n","        )\n","\n","        labels = tf.concat(\n","            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n","        )\n","\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(combined_images)\n","            d_loss = self.loss_fn(labels, predictions)\n","        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n","        self.d_optimizer.apply_gradients(\n","            zip(grads, self.discriminator.trainable_weights)\n","        )\n","\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        random_vector_labels = tf.concat(\n","            [random_latent_vectors, one_hot_labels], axis=1\n","        )\n","\n","        misleading_labels = tf.zeros((batch_size, 1))\n","\n","        with tf.GradientTape() as tape:\n","            fake_images = self.generator(random_vector_labels)\n","            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n","            predictions = self.discriminator(fake_image_and_labels)\n","            g_loss = self.loss_fn(misleading_labels, predictions)\n","        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n","        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n","\n","        self.gen_loss_tracker.update_state(g_loss)\n","        self.disc_loss_tracker.update_state(d_loss)\n","        return {\n","            \"g_loss\": self.gen_loss_tracker.result(),\n","            \"d_loss\": self.disc_loss_tracker.result(),\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"CgTlLdmvJYWC","outputId":"4d8601b9-750e-4135-84fd-40b67c004c22"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","1094/1094 [==============================] - 2715s 2s/step - g_loss: 1.3047 - d_loss: 0.4359\n","Epoch 2/20\n","1094/1094 [==============================] - 2716s 2s/step - g_loss: 1.0412 - d_loss: 0.5933\n","Epoch 3/20\n","1094/1094 [==============================] - 2704s 2s/step - g_loss: 0.9850 - d_loss: 0.6005\n","Epoch 4/20\n","1094/1094 [==============================] - 2704s 2s/step - g_loss: 1.1427 - d_loss: 0.5051\n","Epoch 5/20\n","1094/1094 [==============================] - 2709s 2s/step - g_loss: 1.5707 - d_loss: 0.3443\n","Epoch 6/20\n","1094/1094 [==============================] - 2726s 2s/step - g_loss: 1.9683 - d_loss: 0.3067\n","Epoch 7/20\n"," 898/1094 [=======================>......] - ETA: 8:04 - g_loss: 0.8899 - d_loss: 0.6329"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-9814295747d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcond_gan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Обучение условной ГАН\n","cond_gan = ConditionalGAN(\n","    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",")\n","cond_gan.compile(\n","    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002),\n","    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002),\n","    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",")\n","\n","cond_gan.fit(dataset, epochs=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73A7U9VIJkuh"},"outputs":[],"source":["# Интерполяция между классами с помощью обученного генератора\n","trained_gen = cond_gan.generator\n","\n","num_interpolation = 10  # @param {type:\"integer\"}\n","\n","interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n","interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n","interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n","\n","\n","def interpolate_class(first_number, second_number):\n","    first_label = keras.utils.to_categorical([first_number], n_classes)\n","    second_label = keras.utils.to_categorical([second_number], n_classes)\n","    first_label = tf.cast(first_label, tf.float32)\n","    second_label = tf.cast(second_label, tf.float32)\n","\n","    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n","    percent_second_label = tf.cast(percent_second_label, tf.float32)\n","    interpolation_labels = (\n","        first_label * (1 - percent_second_label) + second_label * percent_second_label\n","    )\n","\n","    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n","    fake = trained_gen.predict(noise_and_labels)\n","    return fake\n","\n","\n","start_class = 9  # @param {type:\"slider\", min:0, max:9, step:1}\n","end_class = 9  # @param {type:\"slider\", min:0, max:9, step:1}\n","\n","fake_images = interpolate_class(start_class, end_class)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOzUzcWlJpCx"},"outputs":[],"source":["fake_images *= 255.0\n","converted_images = fake_images.astype(np.uint8)\n","converted_images = tf.image.resize(converted_images, (96, 96)).numpy().astype(np.uint8)\n","imageio.mimsave(\"animation.gif\", converted_images, fps=1)\n","embed.embed_file(\"animation.gif\")"]}],"metadata":{"colab":{"name":"cGAN-MNIST.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO2etfEFZH6drwPuErq4NtS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}